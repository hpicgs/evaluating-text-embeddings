{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5701bcc-2395-45b6-8546-d112ac921def",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac38236a-54cc-437d-ad18-c3e887ee7c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12892, 14)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"results_cluster/cur_res/full_res_reuters.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdba4e55-d8c3-49ce-94e1-f7ce52de241e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(df):\n",
    "    list_Trustworthiness = df[\"Trustworthiness\"].tolist()\n",
    "    list_Continuity = df[\"Continuity\"].tolist()\n",
    "    list_Shephard = df[\"Shephard Diagram Correlation\"].tolist()\n",
    "\n",
    "    results = []\n",
    "    for i in range(len(list_Trustworthiness)):\n",
    "        results.append(round(0.25*list_Trustworthiness[i] + 0.25*list_Continuity[i] + 0.5*(0.5*(list_Shephard[i] + 1)), 2))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6209b804-c746-4768-bc01-fe8c5a8cb1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_perception(df):\n",
    "    list_NeighborhoodHit = df[\"7-Neighborhood Hit\"].tolist()\n",
    "    list_DistanceConsistency = df[\"Distance consistency\"].tolist()\n",
    "\n",
    "    results = []\n",
    "    for i in range(len(list_NeighborhoodHit)):\n",
    "        results.append(round(0.5*list_NeighborhoodHit[i] + 0.5*list_DistanceConsistency[i], 2))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17779c8-7c94-4692-b3e9-a53d7211a07e",
   "metadata": {},
   "source": [
    "## Generate Entries for Topic Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0234b3a1-1f95-45b5-9b3a-38139dd79a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataframe(corpus_file_layouts, corpus_file_model):\n",
    "    df_layouts_all = pd.read_csv(corpus_file_layouts)\n",
    "    \n",
    "    # only keep the layouts with a topic model, i.e., TM is either lda, lsi, or nmf\n",
    "    excluded_embeddings = ['bert', 'bow', 'tfidf']\n",
    "    df_layouts = df_layouts_all[~df_layouts_all['TM'].isin(excluded_embeddings)]\n",
    "    \n",
    "    # detect the model, i.e., linear combined must be removed\n",
    "    list_TM_short = [TM.replace('_linear_combined', '') for TM in df_layouts[\"TM\"].tolist()]\n",
    "    df_layouts[\"TM_short\"] = list_TM_short\n",
    "    \n",
    "    # detect the number of topics\n",
    "    list_n_topics = [name.split(\"n_topics_\")[1].split(\"_\")[0] for name in df_layouts[\"Experiment\"].tolist()]\n",
    "    df_layouts['n_topics'] = list_n_topics\n",
    "    \n",
    "    # compute the aggregated accuracy\n",
    "    df_layouts[\"accuracy\"] = compute_accuracy(df_layouts)\n",
    "    \n",
    "    # compute the aggregated perception\n",
    "    df_layouts[\"perception\"] = compute_perception(df_layouts)\n",
    "    \n",
    "    # derive the coherence measures\n",
    "    df_model = pd.read_csv(corpus_file_model)\n",
    "    \n",
    "    list_coherence_c_v = []\n",
    "    list_coherence_u_mass = []\n",
    "    list_coherence_c_uci = []\n",
    "    list_coherence_c_npmi = []\n",
    "    \n",
    "    for i in range(df_layouts.shape[0]):\n",
    "        model_type = list_TM_short[i]\n",
    "        n_topics = list_n_topics[i]\n",
    "        list_coherence_c_v.append(df_model[(df_model[\"model_type\"] == model_type) & (df_model[\"n_topics\"] == int(n_topics))]['coherence_c_v'].tolist()[0])\n",
    "        list_coherence_u_mass.append(df_model[(df_model[\"model_type\"] == model_type) & (df_model[\"n_topics\"] == int(n_topics))]['coherence_u_mass'].tolist()[0])\n",
    "        list_coherence_c_uci.append(df_model[(df_model[\"model_type\"] == model_type) & (df_model[\"n_topics\"] == int(n_topics))]['coherence_c_uci'].tolist()[0])\n",
    "        list_coherence_c_npmi.append(df_model[(df_model[\"model_type\"] == model_type) & (df_model[\"n_topics\"] == int(n_topics))]['coherence_c_npmi'].tolist()[0])\n",
    "    \n",
    "    df_layouts['coherence_c_v'] = list_coherence_c_v\n",
    "    df_layouts['coherence_u_mass'] = list_coherence_u_mass\n",
    "    df_layouts['coherence_c_uci'] = list_coherence_c_uci\n",
    "    df_layouts['coherence_c_npmi'] = list_coherence_c_npmi\n",
    "    \n",
    "    return df_layouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101e71a7-cbe3-4d89-9d02-94413507b28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emails = generate_dataframe(corpus_file_layouts = \"results_cluster/cur_res/full_res_emails.csv\", corpus_file_model = \"model_evaluations/model_evaluations/emails_model_evaluation.csv\")\n",
    "df_20newsgroups =  generate_dataframe(corpus_file_layouts = \"results_cluster/cur_res/full_res_20_newsgroups.csv\", corpus_file_model = \"model_evaluations/model_evaluations/20_newsgroups_model_evaluation.csv\")\n",
    "df_bbc = generate_dataframe(corpus_file_layouts = \"results_cluster/cur_res/full_res_bbc_news.csv\", corpus_file_model = \"model_evaluations/model_evaluations/bbc_news_model_evaluation.csv\")\n",
    "df_lyrics = generate_dataframe(corpus_file_layouts = \"results_cluster/cur_res/full_res_lyrics.csv\", corpus_file_model = \"model_evaluations/model_evaluations/lyrics_model_evaluation.csv\")\n",
    "df_reuters = generate_dataframe(corpus_file_layouts = \"results_cluster/cur_res/full_res_reuters.csv\", corpus_file_model = \"model_evaluations/model_evaluations/reuters_model_evaluation.csv\")\n",
    "df_7categories = generate_dataframe(corpus_file_layouts = \"results_cluster/cur_res/full_res_seven_categories.csv\", corpus_file_model = \"model_evaluations/model_evaluations/seven_categories_model_evaluation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3fe65e-cd6b-4821-a7e0-ea5e729ee01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_df = [df_emails, df_20newsgroups, df_bbc, df_lyrics, df_reuters, df_7categories]\n",
    "df = pd.concat(list_df, axis=0, ignore_index=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef79a7f5-83a1-44d1-82d5-7e539db61c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['embedding', 'DR', 'layout_quality_measure', 'embedding_quality_measure', 'value']\n",
    "df_result = pd.DataFrame(columns = columns)\n",
    "\n",
    "TM_list = ['lda', 'lsi', 'lsi_tfidf', 'nmf', 'nmf_tfidf']\n",
    "DR_list = ['mds', 'som', 'tsne', 'umap']\n",
    "\n",
    "for TM in TM_list:\n",
    "    for DR in DR_list:\n",
    "        df_selected = df[(df[\"TM_short\"] == TM) & (df[\"DR\"] == DR)]\n",
    "        list_accuracy = df_selected[\"accuracy\"].tolist()\n",
    "        list_perception = df_selected[\"perception\"].tolist()\n",
    "        \n",
    "        list_coherence_c_v = df_selected[\"coherence_c_v\"].tolist()\n",
    "        value_acc = stats.kendalltau(list_accuracy, list_coherence_c_v)[0]\n",
    "        new_row_acc_c_v = {'embedding': TM, 'DR': DR, 'layout_quality_measure': 'acc', 'embedding_quality_measure': 'c_v', 'value':value_acc}\n",
    "        #df_result.append(new_row_acc_c_v, ignore_index=True)\n",
    "        df_result = pd.concat([df_result, pd.DataFrame([new_row_acc_c_v])], ignore_index=True)\n",
    "        value_per = stats.kendalltau(list_perception, list_coherence_c_v)[0]\n",
    "        new_row_per_c_v = {'embedding': TM, 'DR': DR, 'layout_quality_measure': 'per', 'embedding_quality_measure': 'c_v', 'value':value_per}\n",
    "        #df_result.append(new_row_per_c_v, ignore_index=True)\n",
    "        df_result = pd.concat([df_result, pd.DataFrame([new_row_per_c_v])], ignore_index=True)\n",
    "\n",
    "        \n",
    "        list_coherence_u_mass = df_selected[\"coherence_u_mass\"].tolist()\n",
    "        value_acc = stats.kendalltau(list_accuracy, list_coherence_u_mass)[0]\n",
    "        new_row_acc_u_mass = {'embedding': TM, 'DR': DR, 'layout_quality_measure': 'acc', 'embedding_quality_measure': 'u_mass', 'value':value_acc}\n",
    "        #df_result.append(new_row_acc_u_mass, ignore_index=True)\n",
    "        df_result = pd.concat([df_result, pd.DataFrame([new_row_acc_u_mass])], ignore_index=True)\n",
    "        value_per = stats.kendalltau(list_perception, list_coherence_u_mass)[0]\n",
    "        new_row_per_u_mass = {'embedding': TM, 'DR': DR, 'layout_quality_measure': 'per', 'embedding_quality_measure': 'u_mass', 'value':value_per}\n",
    "        #df_result.append(new_row_per_u_mass, ignore_index=True)\n",
    "        df_result = pd.concat([df_result, pd.DataFrame([new_row_per_u_mass])], ignore_index=True)\n",
    "\n",
    "        \n",
    "        list_coherence_c_uci = df_selected[\"coherence_c_uci\"].tolist()\n",
    "        value_acc = stats.kendalltau(list_accuracy, list_coherence_c_uci)[0]\n",
    "        new_row_acc_c_uci = {'embedding': TM, 'DR': DR, 'layout_quality_measure': 'acc', 'embedding_quality_measure': 'c_uci', 'value':value_acc}\n",
    "        #df_result.append(new_row_acc_c_uci, ignore_index=True)\n",
    "        df_result = pd.concat([df_result, pd.DataFrame([new_row_acc_c_uci])], ignore_index=True)\n",
    "        value_per = stats.kendalltau(list_perception, list_coherence_c_uci)[0]\n",
    "        new_row_per_c_uci = {'embedding': TM, 'DR': DR, 'layout_quality_measure': 'per', 'embedding_quality_measure': 'c_uci', 'value':value_per}\n",
    "        #df_result.append(new_row_per_u_uci, ignore_index=True)\n",
    "        df_result = pd.concat([df_result, pd.DataFrame([new_row_per_c_uci])], ignore_index=True)\n",
    "\n",
    "        \n",
    "        list_coherence_c_npmi = df_selected[\"coherence_c_npmi\"].tolist()\n",
    "        value_acc = stats.kendalltau(list_accuracy, list_coherence_c_npmi)[0]\n",
    "        new_row_acc_c_npmi = {'embedding': TM, 'DR': DR, 'layout_quality_measure': 'acc', 'embedding_quality_measure': 'c_npmi', 'value':value_acc}\n",
    "        #df_result.append(new_row_acc_c_npmi, ignore_index=True)\n",
    "        df_result = pd.concat([df_result, pd.DataFrame([new_row_acc_c_npmi])], ignore_index=True)\n",
    "        value_per = stats.kendalltau(list_perception, list_coherence_c_npmi)[0]\n",
    "        new_row_per_c_npmi = {'embedding': TM, 'DR': DR, 'layout_quality_measure': 'per', 'embedding_quality_measure': 'c_npmi', 'value':value_per}\n",
    "        #df_result.append(new_row_per_c_npmi, ignore_index=True)\n",
    "        df_result = pd.concat([df_result, pd.DataFrame([new_row_per_c_npmi])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a990ad-4ca3-4eac-ac1a-0f74d5c586d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60894a56-4328-4c07-80d5-3bd174af2782",
   "metadata": {},
   "source": [
    "## Bert Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2447a9a2-5233-4ea7-8d31-f32fbb11cf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.sbert.net/docs/sentence_transformer/pretrained_models.html\n",
    "df_quality_bert = pd.DataFrame({'model': ['bert_all-MiniLM-L6-v2', 'bert_all-distilroberta-v1', 'bert_all-mpnet-base-v2', 'bert_paraphrase-MiniLM-L3-v2', 'bert_paraphrase-albert-small-v2'],\n",
    "                               'performance_sentence_embeddings': [68.06, 68.06, 69.57, 62.29, 64.46],\n",
    "                              'performance_semantic_search': [49.54, 50.94, 57.02, 39.19, 40.04]})\n",
    "df_quality_bert.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb88d5e-f263-4d65-a0f3-4019ec775581",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(experiment):\n",
    "    model_list = ['bert_all-MiniLM-L6-v2', 'bert_all-distilroberta-v1', 'bert_all-mpnet-base-v2', 'bert_paraphrase-MiniLM-L3-v2', 'bert_paraphrase-albert-small-v2']\n",
    "    for model in model_list:\n",
    "        if model in experiment:\n",
    "            return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81580177-7492-4845-baa8-d30c0b2b51c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_performance_sentence_embeddings(model):\n",
    "    return df_quality_bert[df_quality_bert[\"model\"] == model][\"performance_sentence_embeddings\"].tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c0742b-e7d0-4e3b-9310-86e5861510ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_performance_semantic_search(model):\n",
    "    return df_quality_bert[df_quality_bert[\"model\"] == model][\"performance_semantic_search\"].tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126689d1-82c8-4696-9d94-5ccd19a49321",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataframe_bert(corpus_file_layouts):\n",
    "    df_layouts_all = pd.read_csv(corpus_file_layouts)\n",
    "    \n",
    "    # only keep the layouts with BERT\n",
    "    df_layouts = df_layouts_all[df_layouts_all['TM'].isin(['bert'])]\n",
    "    \n",
    "    # detect the model\n",
    "    experiments_list = df_layouts[\"Experiment\"].tolist()\n",
    "    model_list = [get_model(experiment) for experiment in experiments_list]\n",
    "    performance_sentence_embedding_list = [get_model_performance_sentence_embeddings(model) for model in model_list]\n",
    "    performance_semantic_search_list = [get_model_performance_semantic_search(model) for model in model_list]\n",
    "\n",
    "    df_layouts[\"performance_sentence_embedding\"] = performance_sentence_embedding_list\n",
    "    df_layouts[\"performance_semantic_search\"] = performance_semantic_search_list\n",
    "    \n",
    "    # compute the aggregated accuracy\n",
    "    df_layouts[\"accuracy\"] = compute_accuracy(df_layouts)\n",
    "    \n",
    "    # compute the aggregated perception\n",
    "    df_layouts[\"perception\"] = compute_perception(df_layouts)\n",
    "    \n",
    "    return df_layouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28bc5f5-9dcf-474a-958e-5c4db9a5843a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emails_bert = generate_dataframe_bert(corpus_file_layouts = \"results_cluster/cur_res/full_res_emails.csv\")\n",
    "df_20newsgroups_bert =  generate_dataframe_bert(corpus_file_layouts = \"results_cluster/cur_res/full_res_20_newsgroups.csv\")\n",
    "df_bbc_bert = generate_dataframe_bert(corpus_file_layouts = \"results_cluster/cur_res/full_res_bbc_news.csv\")\n",
    "df_lyrics_bert = generate_dataframe_bert(corpus_file_layouts = \"results_cluster/cur_res/full_res_lyrics.csv\")\n",
    "df_reuters_bert = generate_dataframe_bert(corpus_file_layouts = \"results_cluster/cur_res/full_res_reuters.csv\")\n",
    "df_7categories_bert = generate_dataframe_bert(corpus_file_layouts = \"results_cluster/cur_res/full_res_seven_categories.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be3f29a-8888-44a1-923f-8e60c487d200",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_df_bert = [df_emails_bert, df_20newsgroups_bert, df_bbc_bert, df_lyrics_bert, df_reuters_bert, df_7categories_bert]\n",
    "df_bert = pd.concat(list_df_bert, axis=0, ignore_index=True)\n",
    "df_bert.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88785749-a0d9-4bb3-a4e6-87e757db9df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bert.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d92c2b2-a99b-47cc-91e2-2f136bec4ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['embedding', 'DR', 'layout_quality_measure', 'embedding_quality_measure', 'value']\n",
    "df_bert_result = pd.DataFrame(columns = columns)\n",
    "\n",
    "TM_list = ['bert']\n",
    "DR_list = ['mds', 'som', 'tsne', 'umap']\n",
    "\n",
    "for TM in TM_list:\n",
    "    for DR in DR_list:\n",
    "        df_selected = df_bert[df_bert[\"DR\"] == DR]\n",
    "        list_accuracy = df_selected[\"accuracy\"].tolist()\n",
    "        list_perception = df_selected[\"perception\"].tolist()\n",
    "        \n",
    "        list_performance_sentence_embeddings = df_selected[\"performance_sentence_embedding\"].tolist()\n",
    "        value_acc = stats.kendalltau(list_accuracy, list_performance_sentence_embeddings)[0]\n",
    "        new_row_acc_sentence_embeddings = {'embedding': TM, 'DR': DR, 'layout_quality_measure': 'acc', 'embedding_quality_measure': 'performance_sentence_embeddings', 'value':value_acc}\n",
    "        #df_result.append(new_row_acc_c_v, ignore_index=True)\n",
    "        df_bert_result = pd.concat([df_bert_result, pd.DataFrame([new_row_acc_sentence_embeddings])], ignore_index=True)\n",
    "        value_per = stats.kendalltau(list_perception, list_performance_sentence_embeddings)[0]\n",
    "        new_row_per_sentence_embeddings = {'embedding': TM, 'DR': DR, 'layout_quality_measure': 'per', 'embedding_quality_measure': 'performance_sentence_embeddings', 'value':value_per}\n",
    "        #df_result.append(new_row_per_c_v, ignore_index=True)\n",
    "        df_bert_result = pd.concat([df_bert_result, pd.DataFrame([new_row_per_sentence_embeddings])], ignore_index=True)\n",
    "\n",
    "\n",
    "        list_performance_semantic_search = df_selected[\"performance_semantic_search\"].tolist()\n",
    "        value_acc = stats.kendalltau(list_accuracy, list_performance_semantic_search)[0]\n",
    "        new_row_acc_semantic_search = {'embedding': TM, 'DR': DR, 'layout_quality_measure': 'acc', 'embedding_quality_measure': 'performance_semantic_search', 'value':value_acc}\n",
    "        #df_result.append(new_row_acc_c_v, ignore_index=True)\n",
    "        df_bert_result = pd.concat([df_bert_result, pd.DataFrame([new_row_acc_semantic_search])], ignore_index=True)\n",
    "        value_per = stats.kendalltau(list_perception, list_performance_semantic_search)[0]\n",
    "        new_row_per_semantic_search = {'embedding': TM, 'DR': DR, 'layout_quality_measure': 'per', 'embedding_quality_measure': 'performance_semantic_search', 'value':value_per}\n",
    "        #df_result.append(new_row_per_c_v, ignore_index=True)\n",
    "        df_bert_result = pd.concat([df_bert_result, pd.DataFrame([new_row_per_semantic_search])], ignore_index=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53f25a6-6305-4058-930b-2511c9466885",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bert_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adee1eb3-0155-4a05-8c4e-332d94051b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total = pd.concat([df_result, df_bert_result], ignore_index = True)\n",
    "df_total.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ee3250-4478-4b53-985b-a5f9d7924154",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total.to_csv(\"results_kendallstau.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1441cdd2-fd75-4833-b894-54cb432f9229",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
